Exorcising the Ghost in the Machine:
Synthetic Spectral Data Cubes for Assessing Big Data Algorithms.

The size and quantity of the data that is being generated by large astronomical
projects like ALMA, requires a paradigm change in astronomical data analysis.
Complex data, such as highly sensitive spectroscopic data in the form of large
data cubes, are not only difficult to manage, transfer and visualize, but they
also turn unfeasible the use of traditional data analysis techniques and
algorithms.  Consequently, the attention have been placed on 
machine learning and artificial intelligence techniques, to develop approximate and
adaptive methods for astronomical data analysis within a reasonable
computational time. 

Unfortunately, these techniques are usually sub-optimal, stochastic and strongly
dependent of the parameters, which could easily turn into "a ghost in the
machine" for astronomers and practitioners. Therefore, a proper assessment of
these methods is not only desirable but mandatory for trusting them in
large-scale usage. The problem is that positively verifiable results are scarce
in astronomy, and moreover, science using bleeding-edge instrumentation
naturally lacks of reference values.

We propose an Astronomical SYnthetic Data Observatory (ASYDO), a virtual service
that generates spectroscopic synthetic data in the form of data cubes. The 
objective of the tool is not to produce accurate astrophysical simulations, 
but to generate a large number of labelled synthetic data, to assess advanced
computing algorithms and to develop new and novel Big Data algorithms. The
synthetic data is generated using a public database of spectral lines, template 
functions for spatial and spectral distributions, and simple models that produce
reasonable synthetic observations. ASYDO's generic implementation supports
new user-made models, which potentially allows more advanced astrophysical models
to be added. We expect to implement ASYDO as a VO service in the near future.

 

#These methods have been successfully applied in
#large astronomical surveys, because uninformed techniques are data consuming and
#need homogeneous data samples. The next step is to develop efficient computing
#models that can encode prior astrophysical knowledge and to support
#heterogeneous data.

